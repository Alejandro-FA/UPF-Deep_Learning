Test results: {'accuracy': [94.53125, 94.140625, 95.703125, 93.75, 95.703125, 93.75, 97.265625, 93.359375, 97.65625, 97.65625, 94.921875, 94.921875, 95.703125, 96.484375, 96.484375, 93.75, 95.3125, 95.3125, 94.140625, 95.703125, 96.09375, 97.65625, 96.484375, 95.3125, 96.09375, 94.921875, 97.65625, 98.828125, 96.09375, 93.75, 96.484375, 93.359375, 92.578125, 97.265625, 94.140625, 94.53125, 98.828125, 94.53125, 96.484375, 94.921875, 96.484375, 95.3125, 95.703125, 92.96875, 96.484375, 95.703125, 93.75, 94.53125, 97.265625, 92.578125, 93.75, 94.921875, 96.484375, 96.09375, 94.921875, 97.265625, 96.484375, 96.875, 97.65625, 94.53125, 95.703125, 93.359375, 95.703125, 97.265625, 96.09375, 95.703125, 94.140625, 94.921875, 96.484375, 93.75, 94.921875, 94.53125, 95.703125, 97.265625, 96.484375, 96.09375, 95.703125, 95.3125, 91.40625, 95.3125, 96.875, 96.875, 95.703125, 96.484375, 96.484375, 94.921875, 94.140625, 96.09375, 96.09375, 94.53125, 95.703125, 96.09375, 94.53125, 96.484375, 97.65625, 93.359375, 95.3125, 98.046875, 93.75, 95.703125, 96.875, 96.02272727272727], 'loss': [0.18960753083229065, 0.163432314991951, 0.21888187527656555, 0.1830953061580658, 0.15730585157871246, 0.376140296459198, 0.14562015235424042, 0.2617451846599579, 0.07585406303405762, 0.13559402525424957, 0.16199351847171783, 0.15857169032096863, 0.3413926064968109, 0.10773205012083054, 0.0960935726761818, 0.3787941038608551, 0.16972190141677856, 0.2811945080757141, 0.1380765438079834, 0.15430358052253723, 0.12007755041122437, 0.1875428706407547, 0.14249414205551147, 0.13642618060112, 0.1856267899274826, 0.3580504059791565, 0.08751116693019867, 0.04659074544906616, 0.11969619989395142, 0.192014679312706, 0.1599150449037552, 0.3827861249446869, 0.60577791929245, 0.12063775956630707, 0.17574262619018555, 0.20715852081775665, 0.061608947813510895, 0.16206945478916168, 0.15190836787223816, 0.2845889925956726, 0.11149406433105469, 0.18297189474105835, 0.17623479664325714, 0.2756248712539673, 0.1068381667137146, 0.1150621697306633, 0.2582269608974457, 0.1919214278459549, 0.09750206768512726, 0.368408203125, 0.192621648311615, 0.16507074236869812, 0.11740981787443161, 0.165719136595726, 0.15912601351737976, 0.2908805310726166, 0.20621395111083984, 0.1322624534368515, 0.06928807497024536, 0.1748817265033722, 0.21200242638587952, 0.4227561950683594, 0.16245269775390625, 0.07734761387109756, 0.1521783024072647, 0.1279142051935196, 0.2882368266582489, 0.20041780173778534, 0.12061768770217896, 0.2483779937028885, 0.16540051996707916, 0.20301052927970886, 0.2503102421760559, 0.10963719338178635, 0.13588875532150269, 0.13604186475276947, 0.13182605803012848, 0.12336503714323044, 0.34896519780158997, 0.17711687088012695, 0.11568059027194977, 0.15307609736919403, 0.185756117105484, 0.15212339162826538, 0.11905987560749054, 0.12513789534568787, 0.13253146409988403, 0.15804067254066467, 0.13052526116371155, 0.30535998940467834, 0.17733852565288544, 0.18960058689117432, 0.3308425843715668, 0.22155459225177765, 0.14052170515060425, 0.22951537370681763, 0.13713589310646057, 0.09676142036914825, 0.16627076268196106, 0.13356617093086243, 0.09878361225128174, 0.10842835158109665]}
Loss function used: CrossEntropyLoss()
Epochs: 5
Optimizer: SGD (
Parameter Group 0
    dampening: 0
    differentiable: False
    foreach: None
    lr: 0.1
    maximize: False
    momentum: 0.9
    nesterov: False
    weight_decay: 1e-05
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
ConvNet                                  [256, 10]                 800
├─Conv2d: 1-1                            [256, 16, 32, 32]         64
├─LeakyReLU: 1-2                         [256, 16, 32, 32]         --
├─Sequential: 1-3                        [256, 16, 32, 32]         --
│    └─Conv2d: 2-1                       [256, 3, 32, 32]          30
│    └─Conv2d: 2-2                       [256, 16, 32, 32]         64
├─LeakyReLU: 1-4                         [256, 16, 32, 32]         --
├─Sequential: 1-5                        [256, 16, 32, 32]         --
│    └─Conv2d: 2-3                       [256, 3, 32, 32]          78
│    └─Conv2d: 2-4                       [256, 16, 32, 32]         64
├─LeakyReLU: 1-6                         [256, 16, 32, 32]         --
├─Sequential: 1-7                        [256, 16, 32, 32]         --
│    └─Conv2d: 2-5                       [256, 3, 32, 32]          150
│    └─Conv2d: 2-6                       [256, 16, 32, 32]         64
├─LeakyReLU: 1-8                         [256, 16, 32, 32]         --
├─MaxPool2d: 1-9                         [256, 64, 15, 15]         --
├─Dropout2d: 1-10                        [256, 64, 15, 15]         --
├─Sequential: 1-11                       [256, 128, 15, 15]        --
│    └─Conv2d: 2-7                       [256, 64, 15, 15]         1,664
│    └─Conv2d: 2-8                       [256, 128, 15, 15]        8,320
├─LeakyReLU: 1-12                        [256, 128, 15, 15]        --
├─Sequential: 1-13                       [256, 128, 15, 15]        --
│    └─Conv2d: 2-9                       [256, 128, 15, 15]        6,400
│    └─Conv2d: 2-10                      [256, 128, 15, 15]        16,512
├─LeakyReLU: 1-14                        [256, 128, 15, 15]        --
├─MaxPool2d: 1-15                        [256, 128, 7, 7]          --
├─Dropout2d: 1-16                        [256, 128, 7, 7]          --
├─Sequential: 1-17                       [256, 196, 7, 7]          --
│    └─Conv2d: 2-11                      [256, 128, 7, 7]          3,328
│    └─Conv2d: 2-12                      [256, 196, 7, 7]          25,284
├─LeakyReLU: 1-18                        [256, 196, 7, 7]          --
├─Sequential: 1-19                       [256, 196, 7, 7]          --
│    └─Conv2d: 2-13                      [256, 196, 7, 7]          5,096
│    └─Conv2d: 2-14                      [256, 196, 7, 7]          38,612
├─LeakyReLU: 1-20                        [256, 196, 7, 7]          --
├─MaxPool2d: 1-21                        [256, 196, 3, 3]          --
├─Dropout: 1-22                          [256, 1764]               --
├─Linear: 1-23                           [256, 10]                 17,650
├─LeakyReLU: 1-24                        [256, 10]                 --
==========================================================================================
Total params: 124,180
Trainable params: 124,180
Non-trainable params: 0
Total mult-adds (G): 2.94
==========================================================================================
Input size (MB): 3.15
Forward/backward pass size (MB): 431.40
Params size (MB): 0.49
Estimated Total Size (MB): 435.04
==========================================================================================